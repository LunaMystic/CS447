{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MP4.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gau9xEXMGY8s","colab_type":"text"},"source":["# Using Attention for Neural Machine Translation\n","In this notebook we are going to perform machine translation using a deep learning based approach and attention mechanism.\n","\n","Specifically, we are going to train a sequence to sequence model for Spanish to English translation.  We will use Sequence to Sequence Models for this Assignment. In this assignment you only need tto implement the encoder and decoder, we implement all the data loading for you.Please **refer** to the following resources for more details:\n","\n","1.   https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n","2.   https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n","3. https://arxiv.org/pdf/1409.0473.pdf\n","\n"]},{"cell_type":"code","metadata":{"id":"H9mf5x3zHp1A","colab_type":"code","outputId":"c7925410-362c-4fbe-a151-6feabbef0783","executionInfo":{"status":"ok","timestamp":1574719941535,"user_tz":360,"elapsed":3020,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import unicodedata\n","import re\n","import time\n","import nltk\n","from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","print(torch.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["1.3.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-XH8nu0ojQpt","colab_type":"text"},"source":["# Download The Data\n","\n","Here we will download the translation data. We will learn a model to translate Spanish to English."]},{"cell_type":"code","metadata":{"id":"ftasb3wEH0gC","colab_type":"code","outputId":"a32e1a23-dd81-4e2a-cc31-b49baeb09514","executionInfo":{"status":"ok","timestamp":1574719973928,"user_tz":360,"elapsed":29313,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j41KgqCVIIjp","colab_type":"code","outputId":"5eb34fd7-ea4a-4955-e648-37a9e3a3c894","executionInfo":{"status":"ok","timestamp":1574719977578,"user_tz":360,"elapsed":604,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd sample_data/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KtyBFlMKIg7g","colab_type":"code","outputId":"2debbe9b-c374-47e9-b69b-995f37c8c810","executionInfo":{"status":"ok","timestamp":1574719982905,"user_tz":360,"elapsed":4215,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["!wget http://www.manythings.org/anki/spa-eng.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2019-11-25 22:12:43--  http://www.manythings.org/anki/spa-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:30::6818:6cc4, ...\n","Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4752884 (4.5M) [application/zip]\n","Saving to: ‘spa-eng.zip’\n","\n","spa-eng.zip         100%[===================>]   4.53M  2.66MB/s    in 1.7s    \n","\n","2019-11-25 22:12:46 (2.66 MB/s) - ‘spa-eng.zip’ saved [4752884/4752884]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nGnC0q_SI5qW","colab_type":"code","outputId":"22df2921-08e5-4beb-a794-84a52534eee4","executionInfo":{"status":"ok","timestamp":1574719985571,"user_tz":360,"elapsed":2006,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["!unzip spa-eng.zip"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Archive:  spa-eng.zip\n","  inflating: _about.txt              \n","  inflating: spa.txt                 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sC4Pg0kgLxqx","colab_type":"code","outputId":"79d23671-f5e5-4e9f-825f-8a8df7cc6f8f","executionInfo":{"status":"ok","timestamp":1574719986090,"user_tz":360,"elapsed":863,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":406}},"source":["f = open('spa.txt', encoding='UTF-8').read().strip().split('\\n')\n","lines = f\n","total_num_examples = 30000 \n","original_word_pairs = [[w for w in l.split('\\t')][:2] for l in lines[:total_num_examples]]\n","data = pd.DataFrame(original_word_pairs, columns=[\"eng\", \"es\"])\n","data # visualizing the data"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>es</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Ve.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Go.</td>\n","      <td>Vete.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Go.</td>\n","      <td>Vaya.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Go.</td>\n","      <td>Váyase.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Hi.</td>\n","      <td>Hola.</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>29995</th>\n","      <td>Stop blaming yourself.</td>\n","      <td>Deja de culparte a ti mismo.</td>\n","    </tr>\n","    <tr>\n","      <th>29996</th>\n","      <td>Summer has just begun.</td>\n","      <td>El verano acaba de comenzar.</td>\n","    </tr>\n","    <tr>\n","      <th>29997</th>\n","      <td>Tadpoles become frogs.</td>\n","      <td>Los renacuajos se convierten en ranas.</td>\n","    </tr>\n","    <tr>\n","      <th>29998</th>\n","      <td>Take a walk every day.</td>\n","      <td>Da un paseo cada día.</td>\n","    </tr>\n","    <tr>\n","      <th>29999</th>\n","      <td>Take care of yourself.</td>\n","      <td>Cuídate.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>30000 rows × 2 columns</p>\n","</div>"],"text/plain":["                          eng                                      es\n","0                         Go.                                     Ve.\n","1                         Go.                                   Vete.\n","2                         Go.                                   Vaya.\n","3                         Go.                                 Váyase.\n","4                         Hi.                                   Hola.\n","...                       ...                                     ...\n","29995  Stop blaming yourself.            Deja de culparte a ti mismo.\n","29996  Summer has just begun.            El verano acaba de comenzar.\n","29997  Tadpoles become frogs.  Los renacuajos se convierten en ranas.\n","29998  Take a walk every day.                   Da un paseo cada día.\n","29999  Take care of yourself.                                Cuídate.\n","\n","[30000 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"k_WR8vEGMQyS","colab_type":"code","colab":{}},"source":["# Converts the unicode file to ascii\n","def unicode_to_ascii(s):\n","    \"\"\"\n","    Normalizes latin chars with accent to their canonical decomposition\n","    \"\"\"\n","    return ''.join(c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn')\n","\n","# Preprocessing the sentence to add the start, end tokens and make them lower-case\n","def preprocess_sentence(w):\n","    w = unicode_to_ascii(w.lower().strip())\n","    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","    w = re.sub(r'[\" \"]+', \" \", w)\n","\n","    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n","    \n","    w = w.rstrip().strip()\n","    w = '<start> ' + w + ' <end>'\n","    return w"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mud7HbQUMUHB","colab_type":"code","outputId":"887c997c-56e4-4658-ee86-8af1e614fc51","executionInfo":{"status":"ok","timestamp":1574719992734,"user_tz":360,"elapsed":1493,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":347}},"source":["# Now we do the preprocessing using pandas and lambdas\n","# Make sure YOU only run this once - if you run it twice it will mess up the data so you will have run the few above cells again\n","data[\"eng\"] = data.eng.apply(lambda w: preprocess_sentence(w))\n","data[\"es\"] = data.es.apply(lambda w: preprocess_sentence(w))\n","data[250:260]"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>es</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>250</th>\n","      <td>&lt;start&gt; be brief . &lt;end&gt;</td>\n","      <td>&lt;start&gt; se breve . &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>251</th>\n","      <td>&lt;start&gt; be brief . &lt;end&gt;</td>\n","      <td>&lt;start&gt; sea breve . &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>252</th>\n","      <td>&lt;start&gt; be brief . &lt;end&gt;</td>\n","      <td>&lt;start&gt; sean breves . &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>253</th>\n","      <td>&lt;start&gt; be quiet . &lt;end&gt;</td>\n","      <td>&lt;start&gt; estate quieto . &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>254</th>\n","      <td>&lt;start&gt; be still . &lt;end&gt;</td>\n","      <td>&lt;start&gt; no te muevas . &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>255</th>\n","      <td>&lt;start&gt; call tom . &lt;end&gt;</td>\n","      <td>&lt;start&gt; llamalo a tomas ! &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>256</th>\n","      <td>&lt;start&gt; call tom . &lt;end&gt;</td>\n","      <td>&lt;start&gt; llamalo a tomas ! &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>257</th>\n","      <td>&lt;start&gt; call tom . &lt;end&gt;</td>\n","      <td>&lt;start&gt; llamenlo a tomas ! &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>258</th>\n","      <td>&lt;start&gt; cheer up ! &lt;end&gt;</td>\n","      <td>&lt;start&gt; animate . &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>259</th>\n","      <td>&lt;start&gt; cheer up . &lt;end&gt;</td>\n","      <td>&lt;start&gt; venga . &lt;end&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          eng                                es\n","250  <start> be brief . <end>          <start> se breve . <end>\n","251  <start> be brief . <end>         <start> sea breve . <end>\n","252  <start> be brief . <end>       <start> sean breves . <end>\n","253  <start> be quiet . <end>     <start> estate quieto . <end>\n","254  <start> be still . <end>      <start> no te muevas . <end>\n","255  <start> call tom . <end>   <start> llamalo a tomas ! <end>\n","256  <start> call tom . <end>   <start> llamalo a tomas ! <end>\n","257  <start> call tom . <end>  <start> llamenlo a tomas ! <end>\n","258  <start> cheer up ! <end>           <start> animate . <end>\n","259  <start> cheer up . <end>             <start> venga . <end>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"IHJw_CyykmMp","colab_type":"text"},"source":["# Vocabulary Class\n","\n","We create a class here for managing our vocabulary as we did in MP2. In this MP, we have a separate class for the vocabulary as we need 2 different vocabularies - one for English and one for Spanish."]},{"cell_type":"code","metadata":{"id":"1h4Q21azMW-T","colab_type":"code","colab":{}},"source":["class Vocab_Lang():\n","    def __init__(self, data):\n","        \"\"\" data is the list of all sentences in the language dataset\"\"\"\n","        self.data = data\n","        self.word2idx = {}\n","        self.idx2word = {}\n","        self.vocab = set()\n","        \n","        self.create_index()\n","        \n","    def create_index(self):\n","        for sentence in self.data:\n","            # update with individual tokens\n","            self.vocab.update(sentence.split(' '))\n","\n","        # add a padding token\n","        self.word2idx['<pad>'] = 0\n","        \n","        # word to index mapping\n","        for index, word in enumerate(self.vocab):\n","            self.word2idx[word] = index + 1 # +1 because of pad token\n","        \n","        # index to word mapping\n","        for word, index in self.word2idx.items():\n","            self.idx2word[index] = word "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QWiv0o-8MmXb","colab_type":"code","colab":{}},"source":["# index language using the class above\n","inp_lang = Vocab_Lang(data[\"es\"].values.tolist())\n","targ_lang = Vocab_Lang(data[\"eng\"].values.tolist())\n","# Vectorize the input and target languages\n","input_tensor = [[inp_lang.word2idx[s] for s in es.split(' ')]  for es in data[\"es\"].values.tolist()]\n","target_tensor = [[targ_lang.word2idx[s] for s in eng.split(' ')]  for eng in data[\"eng\"].values.tolist()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4bsMZzw4MqJC","colab_type":"code","colab":{}},"source":["def max_length(tensor):\n","    return max(len(t) for t in tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8SCw4JM-Mrud","colab_type":"code","colab":{}},"source":["# calculate the max_length of input and output tensor for padding\n","max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8SRtlYCdMtSV","colab_type":"code","colab":{}},"source":["def pad_sequences(x, max_len):\n","    padded = np.zeros((max_len), dtype=np.int64)\n","    if len(x) > max_len: padded[:] = x[:max_len]\n","    else: padded[:len(x)] = x\n","    return padded\n","\n","# pad all the sentences in the dataset with the max_length\n","input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]\n","target_tensor = [pad_sequences(x, max_length_tar) for x in target_tensor]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5YR39L9MwLb","colab_type":"code","colab":{}},"source":["# Creating training and test/val sets using an 80-20 split\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = input_tensor[:24000], input_tensor[24000:], target_tensor[:24000], target_tensor[24000:]\n","\n","assert(len(input_tensor_train)==24000)\n","assert(len(target_tensor_train)==24000)\n","assert(len(input_tensor_val)==6000)\n","assert(len(target_tensor_val)==6000)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2a2c34aFnPOP","colab_type":"text"},"source":["# Dataloader for our Encoder and Decoder\n","\n","We prepare the dataloader and make sure the dataloader returns the source sentence, target sentence and the length of the source sentenc sampled from the training dataset."]},{"cell_type":"code","metadata":{"id":"c797aZAWMzrW","colab_type":"code","colab":{}},"source":["# conver the data to tensors and pass to the Dataloader \n","# to create an batch iterator\n","from torch.utils.data import Dataset, DataLoader\n","class MyData(Dataset):\n","    def __init__(self, X, y):\n","        self.data = X\n","        self.target = y\n","        # TODO: convert this into torch code is possible\n","        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n","        \n","    def __getitem__(self, index):\n","        x = self.data[index]\n","        y = self.target[index]\n","        x_len = self.length[index]\n","        return x,y,x_len\n","    \n","    def __len__(self):\n","        return len(self.data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iwlsuoMSM1uQ","colab_type":"code","colab":{}},"source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 8\n","N_BATCH = BUFFER_SIZE//BATCH_SIZE\n","embedding_dim = 256\n","units = 1024\n","vocab_inp_size = len(inp_lang.word2idx)\n","vocab_tar_size = len(targ_lang.word2idx)\n","\n","train_dataset = MyData(input_tensor_train, target_tensor_train)\n","val_dataset = MyData(input_tensor_val, target_tensor_val)\n","\n","dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n","                     drop_last=True,\n","                     shuffle=True)\n","\n","val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n","                     drop_last=True,\n","                     shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ENeT1fj_2f8t","colab_type":"text"},"source":["# Encoder Model\n","\n","First we build a simple encoder model, which will be very similar to what you did in MP2. But instead of using a fully connected layer as the output, you should the return the output of your recurrent net (GRU/LSTM) as well as the hidden output. They are used in the decoder later.\n"]},{"cell_type":"code","metadata":{"id":"_Sx4QQd3M4XK","colab_type":"code","colab":{}},"source":["## Feel free to change any parameters class definitions as long as you can change the training code, but make sure\n","## evaluation should get the tensor format it expects\n","class Encoder(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","        super(Encoder, self).__init__()\n","        ### TO - DO\n","        self.hidden_size = enc_units\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = 0)\n","        self.lstm = nn.LSTM(input_size=embedding_dim,\n","                             hidden_size=self.hidden_size, bidirectional = True)\n","        \n","    def forward(self, x, lens):\n","        '''\n","        Pseudo-code\n","        - Pass x through an embedding layer\n","        - Make sure x is correctly packed before the recurrent net \n","        - Pass it through the recurrent net\n","        - Make sure the output is unpacked correctly\n","        - return output and hidden states from the recurrent net\n","        - Feel free to play around with dimensions - the training loop should help you determine the dimensions\n","        '''\n","        ### TO - DO\n","        x = x.long().cuda()\n","        embedded = self.embedding(x)\n","        hidden = None\n","        pack_embedded = nn.utils.rnn.pack_padded_sequence(embedded, lens, enforce_sorted=False)\n","        padded_output,(hidden, cell_state)= self.lstm(pack_embedded, hidden)\n","        padded_output, _ = nn.utils.rnn.pad_packed_sequence(padded_output)\n","        output = padded_output.transpose(0,1)\n","        \n","        hidden_cat = torch.cat((hidden[0], hidden[1]), dim = 1)\n","        return output, hidden_cat\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vKwsEWpK2mcT","colab_type":"text"},"source":["# Decoder Model\n","We will implement a Decoder model which uses an attention mechanism. We will implement the decoder as provided in https://arxiv.org/pdf/1409.0473.pdf. **Please read** the links provided above first, at the start of this assignment for review. The pseudo-code for your implementation should be somewhat as follows:\n","\n","\n","\n","1.   The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*. \n","2.   Using the output your encoder you will calculate the score and subsequently the attention using following equations : \n","<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n","<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n","\n","3. Once you have calculated this attention vector, you pass the original input x through a embedding layer. The output of this embedding layer is concatenated with the attention vector which is passed into a GRU.\n","\n","4. Finally you pass the output of the GRU into a fully connected layer with an output size same as that vocab, to see the probability of the most possible word.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"cw84M2LPM-PC","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.hidden_size = enc_units * 2\n","    self.output_size = vocab_size\n","    self.embedding_dim = embedding_dim\n","\n","    self.embedding = nn.Embedding(self.output_size, self.embedding_dim)\n","    \n","    self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n","    self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n","    self.weight = nn.Linear(self.hidden_size, 1)\n","    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","    self.gru = nn.GRU(self.hidden_size + self.embedding_dim, self.hidden_size, batch_first=True)\n","    self.classifier = nn.Linear(self.hidden_size, self.output_size)\n","\n","  def forward(self, inputs, hidden, enc_output):\n","    '''\n","        Pseudo-code\n","        - Calculate the score using the formula shown above using encoder output and hidden output. \n","        Note h_t is the hidden output of the decoder and h_s is the encoder output in the formula\n","        - Calculate the attention weights using softmax and \n","        passing through V - which can be implemented as a fully connected layer\n","        - Finally find c_t which is a context vector where the shape of context_vector should be (batch_size, hidden_size)\n","        - You need to unsqueeze the context_vector for concatenating with x aas listed in Point 3 above\n","        - Pass this concatenated tensor to the GRU and follow as specified in Point 4 above\n","\n","        Returns :\n","        output - shape = (batch_size, vocab)\n","        hidden state - shape = (batch_size, hidden size)\n","    '''\n","    enc_output = enc_output.squeeze()\n","    hidden = hidden.squeeze(0)  ### [batch_size, hidden_size] \n","    # Embed input words\n","    embedded = self.embedding(inputs)\n","    # print(\"embedded\", embedded.shape)\n","    \n","    # Calculating Attention Scores\n","    x = torch.tanh(self.fc_hidden(hidden.unsqueeze(1))+self.fc_encoder(enc_output)) ### [batch_size, max_length, hidden_size]\n","    # print(\"x\", x.shape)\n","    alignment_scores = self.weight(x) ### [batch_size, max_length,1]\n","    # print(\"alignment_scores\", alignment_scores.shape)\n","    \n","    # Calculating Attention weights\n","    attn_weights = F.softmax(alignment_scores, dim=1).squeeze(2).unsqueeze(1)  ### [batch_size, 1, max_length]\n","    # print(\"attn_weights\", attn_weights.shape)\n","    \n","    # Calculating the context vector\n","    context_vector = torch.bmm(attn_weights, enc_output)  ### [batch_size, 1, hidden_size]\n","    # print(\"context_vector\", context_vector.shape)\n","    \n","    # Concatenating context vector with embedded input word\n","    output = torch.cat((embedded, context_vector), dim = 2)   ### [batch_size，1, hidden_size + embedding_size]\n","    # print(\"output\", output.shape)\n","    hidden = hidden.unsqueeze(0)  ### [1, batch_size, hidden_size] \n","    # print(\"hidden\", hidden.shape)\n","    # Through the GRU cell\n","    output, hidden = self.gru(output, hidden) ### [batch_size, 1, hidden_size]\n","    # Through a classifier\n","    output = F.log_softmax(self.classifier(hidden.squeeze(0)), dim=1)\n","    # print(\"output\", output.shape)\n","    return output, hidden, attn_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxYamsE3M6u6","colab_type":"code","colab":{}},"source":["### sort batch function to be able to use with pad_packed_sequence\n","def sort_batch(X, y, lengths):\n","    lengths, indx = lengths.sort(dim=0, descending=True)\n","    X = X[indx]\n","    y = y[indx]\n","    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bp2rKJY4NIzx","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n","\n","def loss_function(real, pred):\n","    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n","    #mask = 1 - np.equal(real, 0) # assign 0 to all above 0 and 1 to all 0s\n","    #print(mask)\n","    mask = real.ge(1).type(torch.cuda.FloatTensor)\n","    \n","    loss_ = criterion(pred, real) * mask \n","    return torch.mean(loss_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IjbsUkcpNK9W","colab_type":"code","colab":{}},"source":["# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","## Feel free to change any parameters class definitions as long as you can change the training code, but make sure\n","## evaluation should get the tensor format it expects, this is only for reference\n","encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n","\n","encoder.to(device)\n","decoder.to(device)\n","\n","optimizer = optim.SGD(list(encoder.parameters()) + list(decoder.parameters()), \n","                       lr=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VaH022cEy03q","colab_type":"text"},"source":["# Train your model\n","\n","You will train your model here.\n","*   Pass the source sentence and their corresponding lengths into the encoder\n","*   Creating the decoder input using <start> tokens\n","*   Now we find out the decoder outputs conditioned on the previous predicted word usually, but in our training we use teacher forcing. Read more about teacher forcing at https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/\n","\n"]},{"cell_type":"code","metadata":{"id":"i9663UYJNMgv","colab_type":"code","outputId":"f3648ff8-e84a-441b-af6e-a4100dd2f5b5","executionInfo":{"status":"ok","timestamp":1574720178941,"user_tz":360,"elapsed":161459,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":603}},"source":["EPOCHS = 1\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","    \n","    encoder.train()\n","    decoder.train()\n","    \n","    total_loss = 0\n","    \n","    for (batch, (inp, targ, inp_len)) in enumerate(dataset):\n","        loss = 0\n","        \n","        xs, ys, lens = sort_batch(inp, targ, inp_len)\n","        enc_output, enc_hidden = encoder(xs.to(device), lens.to(device))\n","        dec_hidden = enc_hidden\n","        \n","        # use teacher forcing - feeding the target as the next input (via dec_input)\n","        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n","        \n","        # run code below for every timestep in the ys batch\n","        for t in range(1, ys.size(1)):\n","            predictions, dec_hidden, _ = decoder(dec_input.to(device), \n","                                         dec_hidden.to(device), \n","                                         enc_output.to(device))\n","            loss += loss_function(ys[:, t].to(device), predictions.to(device))\n","            #loss += loss_\n","            dec_input = ys[:, t].unsqueeze(1)\n","            \n","        \n","        batch_loss = (loss / int(ys.size(1)))\n","        total_loss += batch_loss\n","        \n","        optimizer.zero_grad()\n","        \n","        loss.backward()\n","\n","        ### UPDATE MODEL PARAMETERS\n","        optimizer.step()\n","        \n","        if batch % 100 == 0:\n","            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                         batch,\n","                                                         batch_loss.detach().item()))\n","        \n","        \n","    ### TODO: Save checkpoint for model\n","    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                        total_loss / N_BATCH))\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n","    torch.save(encoder.state_dict(),'./encoder.pth')\n","    torch.save(decoder.state_dict(),'./decoder.pth')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 5.0056\n","Epoch 1 Batch 100 Loss 2.2636\n","Epoch 1 Batch 200 Loss 1.9826\n","Epoch 1 Batch 300 Loss 1.6793\n","Epoch 1 Batch 400 Loss 1.4052\n","Epoch 1 Batch 500 Loss 1.1084\n","Epoch 1 Batch 600 Loss 1.4587\n","Epoch 1 Batch 700 Loss 1.0960\n","Epoch 1 Batch 800 Loss 1.5162\n","Epoch 1 Batch 900 Loss 1.2819\n","Epoch 1 Batch 1000 Loss 1.0916\n","Epoch 1 Batch 1100 Loss 1.6456\n","Epoch 1 Batch 1200 Loss 0.9997\n","Epoch 1 Batch 1300 Loss 1.3759\n","Epoch 1 Batch 1400 Loss 1.3040\n","Epoch 1 Batch 1500 Loss 1.2797\n","Epoch 1 Batch 1600 Loss 1.2738\n","Epoch 1 Batch 1700 Loss 0.9114\n","Epoch 1 Batch 1800 Loss 1.1159\n","Epoch 1 Batch 1900 Loss 0.9139\n","Epoch 1 Batch 2000 Loss 1.1578\n","Epoch 1 Batch 2100 Loss 1.1039\n","Epoch 1 Batch 2200 Loss 0.7620\n","Epoch 1 Batch 2300 Loss 0.7778\n","Epoch 1 Batch 2400 Loss 0.8835\n","Epoch 1 Batch 2500 Loss 1.1731\n","Epoch 1 Batch 2600 Loss 0.9125\n","Epoch 1 Batch 2700 Loss 0.8573\n","Epoch 1 Batch 2800 Loss 1.2353\n","Epoch 1 Batch 2900 Loss 0.7879\n","Epoch 1 Loss 1.2840\n","Time taken for 1 epoch 155.1126148700714 sec\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"49jpC3pje_R3","colab_type":"code","outputId":"7fa1900c-2bb3-41d0-a389-3788e3bf40a1","executionInfo":{"status":"ok","timestamp":1574720251191,"user_tz":360,"elapsed":60684,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":23,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 145605 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.14-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vryt9Iccm_dh","colab_type":"code","colab":{}},"source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbleFDdnnE11","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"drive/HW4\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PB-Mj6K7Fcti","colab_type":"code","colab":{}},"source":["torch.save(encoder.state_dict(),'./encoder.pth')\n","torch.save(decoder.state_dict(),'./decoder.pth')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdnODzSdESdQ","colab_type":"code","outputId":"0b55af6f-5dc5-4356-c694-bc38f6b97fd1","executionInfo":{"status":"error","timestamp":1574666373762,"user_tz":360,"elapsed":212,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":300}},"source":["# encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","# decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n","import sys\n","sys.path.insert(0, './')\n","encoder.load_state_dict(torch.load(saving_path+'encoder.pth'))\n","decoder.load_state_dict(torch.load(saving_path+'decoder.pth'))"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-61a0308c3d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./encoder.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./decoder.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './encoder.pth'"]}]},{"cell_type":"markdown","metadata":{"id":"nw9gCFY01lZ2","colab_type":"text"},"source":["# Evaluation\n","\n","\n","*   We evaluate on the test set.\n","*   In this evaluation, instead of using the concept of teacher forcing, we use the prediction of the decoder as the input to the decoder for the sequence of outputs.\n","\n"]},{"cell_type":"code","metadata":{"id":"1emvSSo0NRbQ","colab_type":"code","outputId":"fa738f0a-7055-43ae-ca8f-88903d984d76","executionInfo":{"status":"ok","timestamp":1574720304736,"user_tz":360,"elapsed":17124,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["start = time.time()\n","\n","encoder.eval()\n","decoder.eval()\n","\n","total_loss = 0\n","\n","final_output = torch.zeros((len(target_tensor_val),max_length_tar))\n","target_output = torch.zeros((len(target_tensor_val),max_length_tar))\n","\n","for (batch, (inp, targ, inp_len)) in enumerate(val_dataset):\n","    loss = 0\n","    xs, ys, lens = sort_batch(inp, targ, inp_len)\n","    enc_output, enc_hidden = encoder(xs.to(device), lens.to(device))\n","    dec_hidden = enc_hidden\n","    \n","    dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n","    curr_output = torch.zeros((ys.size(0), ys.size(1)))\n","    curr_output[:, 0] = dec_input.squeeze(1)\n","\n","    for t in range(1, ys.size(1)): # run code below for every timestep in the ys batch\n","        predictions, dec_hidden, _ = decoder(dec_input.to(device), \n","                                      dec_hidden.to(device), \n","                                      enc_output.to(device))\n","        loss += loss_function(ys[:, t].to(device), predictions.to(device))\n","        dec_input = torch.argmax(predictions, dim=1).unsqueeze(1)\n","        curr_output[:, t] = dec_input.squeeze(1)\n","    final_output[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE] = curr_output\n","    target_output[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE] = targ\n","    batch_loss = (loss / int(ys.size(1)))\n","    total_loss += batch_loss\n","\n","print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                    total_loss / N_BATCH))\n","print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Epoch 1 Loss 0.9447\n","Time taken for 1 epoch 16.613391399383545 sec\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VQKYT5w3n82V","colab_type":"text"},"source":["# Bleu Score Calculation for evaluation\n","\n","Read more about Bleu Score at :\n","\n","\n","1.   https://en.wikipedia.org/wiki/BLEU\n","2.   https://www.aclweb.org/anthology/P02-1040.pdf\n","\n","We expect your BLEU Scores to be in the range of for full credit. No partial credit :( \n","\n","\n","*   BLEU-1 > 0.14\n","*   BLEU-2 > 0.08\n","*   BLEU-3 > 0.02\n","*   BLEU-4 > 0.15\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"OPosimvgdx_O","colab_type":"code","colab":{}},"source":["def get_reference_candidate(target, pred):\n","  reference = list(target)\n","  reference = [targ_lang.idx2word[s] for s in np.array(reference[1:])]\n","  candidate = list(pred)\n","  candidate = [targ_lang.idx2word[s] for s in np.array(candidate[1:])]\n","  return reference, candidate"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P6NzFQ16fZAc","colab_type":"code","outputId":"df61eea0-7cc2-4ef0-eba6-2ae7a23d6c2e","executionInfo":{"status":"ok","timestamp":1574720529419,"user_tz":360,"elapsed":13931,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["bleu_1 = 0.0\n","bleu_2 = 0.0\n","bleu_3 = 0.0\n","bleu_4 = 0.0\n","smoother = SmoothingFunction()\n","save_reference = []\n","save_candidate = []\n","\n","for i in range(len(target_tensor_val)):\n","  reference, candidate = get_reference_candidate(target_output[i], final_output[i])\n","  #print(reference)\n","  #print(candidate)\n","  save_reference.append(reference)\n","  save_candidate.append(candidate)\n","\n","  bleu_1 += sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoother.method1)\n","  bleu_2 += sentence_bleu(reference, candidate, weights=(0, 1, 0, 0), smoothing_function=smoother.method2)\n","  bleu_3 += sentence_bleu(reference, candidate, weights=(0, 0, 1, 0), smoothing_function=smoother.method3)\n","  bleu_4 += sentence_bleu(reference, candidate, weights=(0, 0, 0, 1), smoothing_function=smoother.method4)\n","\n","print('Individual 1-gram: %f' % (bleu_1/len(target_tensor_val)))\n","print('Individual 2-gram: %f' % (bleu_2/len(target_tensor_val)))\n","print('Individual 3-gram: %f' % (bleu_3/len(target_tensor_val)))\n","print('Individual 4-gram: %f' % (bleu_4/len(target_tensor_val)))\n","assert(len(save_reference)==len(target_tensor_val))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Individual 1-gram: 0.158788\n","Individual 2-gram: 0.098452\n","Individual 3-gram: 0.030766\n","Individual 4-gram: 0.189989\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nYKSWRO93Mjz","colab_type":"text"},"source":["# Save File for Submission\n","You just need to submit your **results.pickle** file to the autograder."]},{"cell_type":"code","metadata":{"id":"R2Jnt32ItMA7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1baca4eb-644c-4e67-f8cb-f9dca6762504","executionInfo":{"status":"ok","timestamp":1574720556151,"user_tz":360,"elapsed":2589,"user":{"displayName":"Xiyu Wang","photoUrl":"","userId":"07901234843404723215"}}},"source":["# import pickle\n","# from google.colab import drive\n","# drive.mount('/content/drive')"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f_VdTMfb1M5S","colab_type":"code","colab":{}},"source":["with open('./results.pickle', 'wb') as fil:\n","    pickle.dump(save_candidate, fil)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kAjOjpQjqNlg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}